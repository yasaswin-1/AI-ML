import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

file_path = '/content/car_evaluation.csv'  # Update with the correct file path
car_data = pd.read_csv(file_path)

le = LabelEncoder()
for col in car_data.columns:
    car_data[col] = le.fit_transform(car_data[col])

X = car_data.drop('outcome', axis=1)
y = car_data['outcome']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

svc_model = SVC(kernel='rbf', probability=True, random_state=42)
svc_model.fit(X_train, y_train)
svc_pred = svc_model.predict(X_test)
svc_acc = accuracy_score(y_test, svc_pred)
print("\nðŸ”¹ SVC Accuracy:", svc_acc)
print(classification_report(y_test, svc_pred))

lr_model = LogisticRegression(max_iter=200, random_state=42)
lr_model.fit(X_train, y_train)
lr_pred = lr_model.predict(X_test)
lr_acc = accuracy_score(y_test, lr_pred)
print("\nðŸ”¹ Logistic Regression Accuracy:", lr_acc)
print(classification_report(y_test, lr_pred))

rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
rf_pred = rf_model.predict(X_test)
rf_acc = accuracy_score(y_test, rf_pred)
print("\nðŸ”¹ Random Forest Accuracy:", rf_acc)
print(classification_report(y_test, rf_pred))

voting_model = VotingClassifier(estimators=[
    ('svc', svc_model),
    ('lr', lr_model),
    ('rf', rf_model)
], voting='hard')

voting_model.fit(X_train, y_train)
voting_pred = voting_model.predict(X_test)
voting_acc = accuracy_score(y_test, voting_pred)
print("\nðŸ”¹ Voting Classifier Accuracy:", voting_acc)
print(classification_report(y_test, voting_pred))

print("\nConfusion Matrix - SVC:\n", confusion_matrix(y_test, svc_pred))
print("\nConfusion Matrix - Logistic Regression:\n", confusion_matrix(y_test, lr_pred))
print("\nConfusion Matrix - Random Forest:\n", confusion_matrix(y_test, rf_pred))
print("\nConfusion Matrix - Voting Classifier:\n", confusion_matrix(y_test, voting_pred))

conf_matrices = {
    "SVC": confusion_matrix(y_test, svc_pred),
    "Logistic Regression": confusion_matrix(y_test, lr_pred),
    "Random Forest": confusion_matrix(y_test, rf_pred),
    "Voting Classifier": confusion_matrix(y_test, voting_pred)
}

# Accuracy Visualization
models = ['SVC', 'Logistic Regression', 'Random Forest', 'Voting Classifier']
accuracies = [svc_acc, lr_acc, rf_acc, voting_acc]

plt.figure(figsize=(12, 6))
sns.barplot(x=models, y=accuracies, palette='viridis')
plt.title('Model Accuracy Comparison')
plt.ylabel('Accuracy')
plt.ylim(0, 1)
plt.show()

# Confusion Matrix Visualization
fig, axes = plt.subplots(2, 2, figsize=(12, 12))

for ax, (model, matrix) in zip(axes.flatten(), conf_matrices.items()):
    sns.heatmap(matrix, annot=True, fmt="d", cmap="Blues", ax=ax)
    ax.set_title(f'{model} - Confusion Matrix')
    ax.set_xlabel('Predicted Label')
    ax.set_ylabel('True Label')

plt.tight_layout()
plt.show()

# Display Classification Report as DataFrame
def display_classification_report(model_name, y_test, y_pred):
    report = classification_report(y_test, y_pred, output_dict=True)
    report_df = pd.DataFrame(report).transpose()
    print(f"\nðŸ”¹ {model_name} Classification Report:\n")
    print(report_df)

# Print Classification Reports
display_classification_report("SVC", y_test, svc_pred)
display_classification_report("Logistic Regression", y_test, lr_pred)
display_classification_report("Random Forest", y_test, rf_pred)
display_classification_report("Voting Classifier", y_test, voting_pred)